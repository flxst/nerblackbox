{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview nerblackbox - a python package to fine-tune transformer-based language models for Named Entity Recognition (NER). Latest version: 0.0.9 Resources Source Code: https://github.com/af-ai-center/nerblackbox Documentation: https://af-ai-center.github.io/nerblackbox PyPI: https://pypi.org/project/nerblackbox About Transformer-based language models like BERT have had a game-changing impact on Natural Language Processing. In order to utilize Hugging Face's publicly accessible pretrained models for Named Entity Recognition , one needs to retrain (or \"fine-tune\") them using labeled text. nerblackbox makes this easy. You give it a Dataset (labeled text) a Pretrained Model (transformers) and you get the best Fine-tuned Model its Performance on the dataset Installation pip install nerblackbox Usage Specify the dataset and pretrained model in an Experiment Configuration File my_experiment.ini dataset_name = swedish_ner_corpus pretrained_model_name = af-ai-center/bert-base-swedish-uncased and use either the Command Line Interface (CLI) or the Python API for fine-tuning and model application: fine-tuning and model application CLI nerbb run_experiment my_experiment # fine-tune nerbb get_experiment_results my_experiment # get results/performance nerbb predict my_experiment annotera den h\u00e4r texten # apply best model for NER Python nerbb = NerBlackBox () nerbb . run_experiment ( \"my_experiment\" ) # fine-tune nerbb . get_experiment_results ( \"my_experiment\" ) # get results/performance nerbb . predict ( \"my_experiment\" , \"annotera den h\u00e4r texten\" ) # apply best model for NER See Guide for more details. Features GPU Support Hyperparameter Search Early Stopping Multiple Identical Runs Language Agnosticism Based on: Hugging Face Transformers , PyTorch Lightning , MLfflow","title":"Overview"},{"location":"#overview","text":"nerblackbox - a python package to fine-tune transformer-based language models for Named Entity Recognition (NER). Latest version: 0.0.9","title":"Overview"},{"location":"#resources","text":"Source Code: https://github.com/af-ai-center/nerblackbox Documentation: https://af-ai-center.github.io/nerblackbox PyPI: https://pypi.org/project/nerblackbox","title":"Resources"},{"location":"#about","text":"Transformer-based language models like BERT have had a game-changing impact on Natural Language Processing. In order to utilize Hugging Face's publicly accessible pretrained models for Named Entity Recognition , one needs to retrain (or \"fine-tune\") them using labeled text. nerblackbox makes this easy. You give it a Dataset (labeled text) a Pretrained Model (transformers) and you get the best Fine-tuned Model its Performance on the dataset","title":"About"},{"location":"#installation","text":"pip install nerblackbox","title":"Installation"},{"location":"#usage","text":"Specify the dataset and pretrained model in an Experiment Configuration File my_experiment.ini dataset_name = swedish_ner_corpus pretrained_model_name = af-ai-center/bert-base-swedish-uncased and use either the Command Line Interface (CLI) or the Python API for fine-tuning and model application: fine-tuning and model application CLI nerbb run_experiment my_experiment # fine-tune nerbb get_experiment_results my_experiment # get results/performance nerbb predict my_experiment annotera den h\u00e4r texten # apply best model for NER Python nerbb = NerBlackBox () nerbb . run_experiment ( \"my_experiment\" ) # fine-tune nerbb . get_experiment_results ( \"my_experiment\" ) # get results/performance nerbb . predict ( \"my_experiment\" , \"annotera den h\u00e4r texten\" ) # apply best model for NER See Guide for more details.","title":"Usage"},{"location":"#features","text":"GPU Support Hyperparameter Search Early Stopping Multiple Identical Runs Language Agnosticism Based on: Hugging Face Transformers , PyTorch Lightning , MLfflow","title":"Features"},{"location":"api_documentation/cli/","text":"Command Line Interface nerbb Usage: nerbb [OPTIONS] COMMAND [ARGS]... Options: --data_dir TEXT [str] relative path of data directory --modify / --no-modify [bool] if flag=set_up_dataset --val_fraction FLOAT [float] if flag=set_up_dataset --verbose / --no-verbose [bool] if flag=set_up_dataset --run_name TEXT [str] if flag=run_experiment --device TEXT [str] if flag=run_experiment --fp16 / --no-fp16 [bool] if flag=run_experiment --results / --no-results [bool] if flag=clear_data analyze_data analyze a dataset. Usage: nerbb analyze_data [OPTIONS] DATASET_NAME clear_data clear data (checkpoints and optionally results). Usage: nerbb clear_data [OPTIONS] download download & prepare built-in datasets, prepare experiment configuration. needs to be called exactly once before any other CLI/API commands of the package are executed in case built-in datasets shall be used. Usage: nerbb download [OPTIONS] get_experiment_results get results for a single experiment. Usage: nerbb get_experiment_results [OPTIONS] EXPERIMENT_NAME get_experiments get overview on experiments. Usage: nerbb get_experiments [OPTIONS] get_experiments_results get results for multiple experiments. Usage: nerbb get_experiments_results [OPTIONS] init initialize the data_dir directory. needs to be called exactly once before any other CLI/API commands of the package are executed. Usage: nerbb init [OPTIONS] mlflow show detailed experiment results in mlflow (port = 5000). Usage: nerbb mlflow [OPTIONS] predict predict labels for text_input using the best model of a single experiment. Usage: nerbb predict [OPTIONS] EXPERIMENT_NAME TEXT_INPUT run_experiment run a single experiment. Usage: nerbb run_experiment [OPTIONS] EXPERIMENT_NAME set_up_dataset set up a dataset using the associated Formatter class. Usage: nerbb set_up_dataset [OPTIONS] DATASET_NAME show_experiment_config show a single experiment configuration in detail. Usage: nerbb show_experiment_config [OPTIONS] EXPERIMENT_NAME show_experiment_configs show overview on all available experiment configurations. Usage: nerbb show_experiment_configs [OPTIONS] tensorboard show detailed experiment results in tensorboard. (port = 6006). Usage: nerbb tensorboard [OPTIONS]","title":"Command Line Interface"},{"location":"api_documentation/cli/#command-line-interface","text":"","title":"Command Line Interface"},{"location":"api_documentation/cli/#nerbb","text":"Usage: nerbb [OPTIONS] COMMAND [ARGS]... Options: --data_dir TEXT [str] relative path of data directory --modify / --no-modify [bool] if flag=set_up_dataset --val_fraction FLOAT [float] if flag=set_up_dataset --verbose / --no-verbose [bool] if flag=set_up_dataset --run_name TEXT [str] if flag=run_experiment --device TEXT [str] if flag=run_experiment --fp16 / --no-fp16 [bool] if flag=run_experiment --results / --no-results [bool] if flag=clear_data","title":"nerbb"},{"location":"api_documentation/cli/#analyze_data","text":"analyze a dataset. Usage: nerbb analyze_data [OPTIONS] DATASET_NAME","title":"analyze_data"},{"location":"api_documentation/cli/#clear_data","text":"clear data (checkpoints and optionally results). Usage: nerbb clear_data [OPTIONS]","title":"clear_data"},{"location":"api_documentation/cli/#download","text":"download & prepare built-in datasets, prepare experiment configuration. needs to be called exactly once before any other CLI/API commands of the package are executed in case built-in datasets shall be used. Usage: nerbb download [OPTIONS]","title":"download"},{"location":"api_documentation/cli/#get_experiment_results","text":"get results for a single experiment. Usage: nerbb get_experiment_results [OPTIONS] EXPERIMENT_NAME","title":"get_experiment_results"},{"location":"api_documentation/cli/#get_experiments","text":"get overview on experiments. Usage: nerbb get_experiments [OPTIONS]","title":"get_experiments"},{"location":"api_documentation/cli/#get_experiments_results","text":"get results for multiple experiments. Usage: nerbb get_experiments_results [OPTIONS]","title":"get_experiments_results"},{"location":"api_documentation/cli/#init","text":"initialize the data_dir directory. needs to be called exactly once before any other CLI/API commands of the package are executed. Usage: nerbb init [OPTIONS]","title":"init"},{"location":"api_documentation/cli/#mlflow","text":"show detailed experiment results in mlflow (port = 5000). Usage: nerbb mlflow [OPTIONS]","title":"mlflow"},{"location":"api_documentation/cli/#predict","text":"predict labels for text_input using the best model of a single experiment. Usage: nerbb predict [OPTIONS] EXPERIMENT_NAME TEXT_INPUT","title":"predict"},{"location":"api_documentation/cli/#run_experiment","text":"run a single experiment. Usage: nerbb run_experiment [OPTIONS] EXPERIMENT_NAME","title":"run_experiment"},{"location":"api_documentation/cli/#set_up_dataset","text":"set up a dataset using the associated Formatter class. Usage: nerbb set_up_dataset [OPTIONS] DATASET_NAME","title":"set_up_dataset"},{"location":"api_documentation/cli/#show_experiment_config","text":"show a single experiment configuration in detail. Usage: nerbb show_experiment_config [OPTIONS] EXPERIMENT_NAME","title":"show_experiment_config"},{"location":"api_documentation/cli/#show_experiment_configs","text":"show overview on all available experiment configurations. Usage: nerbb show_experiment_configs [OPTIONS]","title":"show_experiment_configs"},{"location":"api_documentation/cli/#tensorboard","text":"show detailed experiment results in tensorboard. (port = 6006). Usage: nerbb tensorboard [OPTIONS]","title":"tensorboard"},{"location":"api_documentation/python_api/experiment_results/","text":"ExperimentResults class that contains results of a single experiment. __init__ ( self , experiment = None , single_runs = None , average_runs = None , best_single_run = None , best_average_run = None , best_model = None ) special Parameters: Name Type Description Default experiment Optional[pandas.core.frame.DataFrame] overview on experiment parameters None single_runs Optional[pandas.core.frame.DataFrame] overview on run parameters & single results None average_runs Optional[pandas.core.frame.DataFrame] overview on run parameters & average results None best_single_run Optional[Dict] overview on best run parameters & single results None best_average_run Optional[Dict] overview on best run parameters & average results None best_model Optional[nerblackbox.modules.ner_training.ner_model_predict.NerModelPredict] best model None","title":"ExperimentResults"},{"location":"api_documentation/python_api/experiment_results/#experimentresults","text":"class that contains results of a single experiment.","title":"ExperimentResults"},{"location":"api_documentation/python_api/experiment_results/#nerblackbox.modules.experiment_results.ExperimentResults.__init__","text":"Parameters: Name Type Description Default experiment Optional[pandas.core.frame.DataFrame] overview on experiment parameters None single_runs Optional[pandas.core.frame.DataFrame] overview on run parameters & single results None average_runs Optional[pandas.core.frame.DataFrame] overview on run parameters & average results None best_single_run Optional[Dict] overview on best run parameters & single results None best_average_run Optional[Dict] overview on best run parameters & average results None best_model Optional[nerblackbox.modules.ner_training.ner_model_predict.NerModelPredict] best model None","title":"__init__()"},{"location":"api_documentation/python_api/experiments_results/","text":"ExperimentsResults class that contains results of multiple experiments. __init__ ( self , best_single_runs = None , best_average_runs = None ) special Parameters: Name Type Description Default best_single_runs Optional[pandas.core.frame.DataFrame] overview on best single runs None best_average_runs Optional[pandas.core.frame.DataFrame] overview on best average runs None","title":"ExperimentsResults"},{"location":"api_documentation/python_api/experiments_results/#experimentsresults","text":"class that contains results of multiple experiments.","title":"ExperimentsResults"},{"location":"api_documentation/python_api/experiments_results/#nerblackbox.modules.experiments_results.ExperimentsResults.__init__","text":"Parameters: Name Type Description Default best_single_runs Optional[pandas.core.frame.DataFrame] overview on best single runs None best_average_runs Optional[pandas.core.frame.DataFrame] overview on best average runs None","title":"__init__()"},{"location":"api_documentation/python_api/ner_model_predict/","text":"NerModelPredict class that predicts tags for given text __init__ ( self , hparams ) special Parameters: Name Type Description Default hparams Namespace attr experiment_name, run_name, pretrained_model_name, dataset_name, .. required load_from_checkpoint ( checkpoint_path ) classmethod load model in inference mode from checkpoint_path Parameters: Name Type Description Default checkpoint_path str path to checkpoint required Returns: Type Description NerModelPredict model loaded from checkpoint predict ( self , examples ) predict tags Parameters: Name Type Description Default examples List[str] e.g. [\"example 1\", \"example 2\"] required Returns: Type Description List[argparse.Namespace] predictions: with .internal [list] of (word, tag) tuples and .external [list] of (word, tag) tuples predict_proba ( self , examples ) predict probabilities for tags Parameters: Name Type Description Default examples List[str] e.g. [\"example 1\", \"example 2\"] required Returns: Type Description List[argparse.Namespace] predictions: with .internal [list] of (word, proba_dist) tuples and .external [list] of (word, proba_dist) tuples where proba_dist = [dict] that maps self.tag_list to probabilities","title":"NerModelPredict"},{"location":"api_documentation/python_api/ner_model_predict/#nermodelpredict","text":"class that predicts tags for given text","title":"NerModelPredict"},{"location":"api_documentation/python_api/ner_model_predict/#nerblackbox.modules.ner_training.ner_model_predict.NerModelPredict.__init__","text":"Parameters: Name Type Description Default hparams Namespace attr experiment_name, run_name, pretrained_model_name, dataset_name, .. required","title":"__init__()"},{"location":"api_documentation/python_api/ner_model_predict/#nerblackbox.modules.ner_training.ner_model_predict.NerModelPredict.load_from_checkpoint","text":"load model in inference mode from checkpoint_path Parameters: Name Type Description Default checkpoint_path str path to checkpoint required Returns: Type Description NerModelPredict model loaded from checkpoint","title":"load_from_checkpoint()"},{"location":"api_documentation/python_api/ner_model_predict/#nerblackbox.modules.ner_training.ner_model_predict.NerModelPredict.predict","text":"predict tags Parameters: Name Type Description Default examples List[str] e.g. [\"example 1\", \"example 2\"] required Returns: Type Description List[argparse.Namespace] predictions: with .internal [list] of (word, tag) tuples and .external [list] of (word, tag) tuples","title":"predict()"},{"location":"api_documentation/python_api/ner_model_predict/#nerblackbox.modules.ner_training.ner_model_predict.NerModelPredict.predict_proba","text":"predict probabilities for tags Parameters: Name Type Description Default examples List[str] e.g. [\"example 1\", \"example 2\"] required Returns: Type Description List[argparse.Namespace] predictions: with .internal [list] of (word, proba_dist) tuples and .external [list] of (word, proba_dist) tuples where proba_dist = [dict] that maps self.tag_list to probabilities","title":"predict_proba()"},{"location":"api_documentation/python_api/nerblackbox/","text":"NerBlackBox class that provides all nerblackbox functionalities. __init__ ( self , base_dir = '.' , data_dir = './data' ) special Parameters: Name Type Description Default base_dir str relative path of base directory with respect to current directory '.' data_dir str relative path of data directory with respect to current directory './data' analyze_data ( self , dataset_name , ** kwargs_optional ) analyze a dataset. Parameters: Name Type Description Default dataset_name str e.g. \"swedish_ner_corpus\". required kwargs_optional Dict with optional key-value pairs {\"verbose\": [bool]}. {} download ( self ) download & prepare built-in datasets, prepare experiment configuration. needs to be called exactly once before any other CLI/API commands of the package are executed in case built-in datasets shall be used. get_experiment_results ( self , experiment_name ) get results for a single experiment. Parameters: Name Type Description Default experiment_name str e.g. \"exp0\" required get_experiments ( self , ** kwargs_optional ) show list of experiments that have been run. Parameters: Name Type Description Default kwargs_optional Dict with optional key-value pairs {\"ids\": [tuple of int], \"as_df\": [bool]} {} Returns: Type Description DataFrame experiments_overview: overview get_experiments_results ( self , ** kwargs_optional ) get results from multiple experiments. Parameters: Name Type Description Default kwargs_optional Dict with optional key-value pairs {\"ids\": [tuple of int], \"as_df\": [bool]} {} Returns: Type Description Dict experiments_results: w/ keys = \"best_single_runs\", \"best_average_runs\" & values = [pandas DataFrame] or [dict] init ( self ) initialize the data_dir directory. needs to be called exactly once before any other CLI/API commands of the package are executed. predict ( self , experiment_name , text_input ) predict labels for text_input using the best model of a single experiment. Parameters: Name Type Description Default experiment_name str e.g. \"exp0\" required text_input Union[str, List[str]] e.g. \"this text needs to be tagged\" required run_experiment ( self , experiment_name , ** kwargs_optional ) run a single experiment. Parameters: Name Type Description Default experiment_name str e.g. \"exp0\" required kwargs_optional Dict with optional key-value pairs {\"run_name\": [str], \"device\": [torch device], \"fp16\": [bool]} {} set_up_dataset ( self , dataset_name , ** kwargs_optional ) set up a dataset using the associated Formatter class. Parameters: Name Type Description Default dataset_name str e.g. \"swedish_ner_corpus\" required kwargs_optional Dict with optional key-value pairs {\"modify\": [bool], \"val_fraction\": [float], \"verbose\": [bool]} {} show_experiment_config ( self , experiment_name ) show a single experiment configuration in detail. Parameters: Name Type Description Default experiment_name str e.g. \"exp0\" required show_experiment_configs ( self ) show overview on all available experiment configurations.","title":"NerBlackBox"},{"location":"api_documentation/python_api/nerblackbox/#nerblackbox","text":"class that provides all nerblackbox functionalities.","title":"NerBlackBox"},{"location":"api_documentation/python_api/nerblackbox/#nerblackbox.api.NerBlackBox.__init__","text":"Parameters: Name Type Description Default base_dir str relative path of base directory with respect to current directory '.' data_dir str relative path of data directory with respect to current directory './data'","title":"__init__()"},{"location":"api_documentation/python_api/nerblackbox/#nerblackbox.api.NerBlackBox.analyze_data","text":"analyze a dataset. Parameters: Name Type Description Default dataset_name str e.g. \"swedish_ner_corpus\". required kwargs_optional Dict with optional key-value pairs {\"verbose\": [bool]}. {}","title":"analyze_data()"},{"location":"api_documentation/python_api/nerblackbox/#nerblackbox.api.NerBlackBox.download","text":"download & prepare built-in datasets, prepare experiment configuration. needs to be called exactly once before any other CLI/API commands of the package are executed in case built-in datasets shall be used.","title":"download()"},{"location":"api_documentation/python_api/nerblackbox/#nerblackbox.api.NerBlackBox.get_experiment_results","text":"get results for a single experiment. Parameters: Name Type Description Default experiment_name str e.g. \"exp0\" required","title":"get_experiment_results()"},{"location":"api_documentation/python_api/nerblackbox/#nerblackbox.api.NerBlackBox.get_experiments","text":"show list of experiments that have been run. Parameters: Name Type Description Default kwargs_optional Dict with optional key-value pairs {\"ids\": [tuple of int], \"as_df\": [bool]} {} Returns: Type Description DataFrame experiments_overview: overview","title":"get_experiments()"},{"location":"api_documentation/python_api/nerblackbox/#nerblackbox.api.NerBlackBox.get_experiments_results","text":"get results from multiple experiments. Parameters: Name Type Description Default kwargs_optional Dict with optional key-value pairs {\"ids\": [tuple of int], \"as_df\": [bool]} {} Returns: Type Description Dict experiments_results: w/ keys = \"best_single_runs\", \"best_average_runs\" & values = [pandas DataFrame] or [dict]","title":"get_experiments_results()"},{"location":"api_documentation/python_api/nerblackbox/#nerblackbox.api.NerBlackBox.init","text":"initialize the data_dir directory. needs to be called exactly once before any other CLI/API commands of the package are executed.","title":"init()"},{"location":"api_documentation/python_api/nerblackbox/#nerblackbox.api.NerBlackBox.predict","text":"predict labels for text_input using the best model of a single experiment. Parameters: Name Type Description Default experiment_name str e.g. \"exp0\" required text_input Union[str, List[str]] e.g. \"this text needs to be tagged\" required","title":"predict()"},{"location":"api_documentation/python_api/nerblackbox/#nerblackbox.api.NerBlackBox.run_experiment","text":"run a single experiment. Parameters: Name Type Description Default experiment_name str e.g. \"exp0\" required kwargs_optional Dict with optional key-value pairs {\"run_name\": [str], \"device\": [torch device], \"fp16\": [bool]} {}","title":"run_experiment()"},{"location":"api_documentation/python_api/nerblackbox/#nerblackbox.api.NerBlackBox.set_up_dataset","text":"set up a dataset using the associated Formatter class. Parameters: Name Type Description Default dataset_name str e.g. \"swedish_ner_corpus\" required kwargs_optional Dict with optional key-value pairs {\"modify\": [bool], \"val_fraction\": [float], \"verbose\": [bool]} {}","title":"set_up_dataset()"},{"location":"api_documentation/python_api/nerblackbox/#nerblackbox.api.NerBlackBox.show_experiment_config","text":"show a single experiment configuration in detail. Parameters: Name Type Description Default experiment_name str e.g. \"exp0\" required","title":"show_experiment_config()"},{"location":"api_documentation/python_api/nerblackbox/#nerblackbox.api.NerBlackBox.show_experiment_configs","text":"show overview on all available experiment configurations.","title":"show_experiment_configs()"},{"location":"api_documentation/python_api/overview/","text":"Python API Available Classes: NerBlackBox ExperimentResults ExperimentsResults NerModelPredict Usage: Python from nerblackbox import NerBlackBox , ExperimentResults , ExperimentsResults , NerModelPredict","title":"Overview"},{"location":"api_documentation/python_api/overview/#python-api","text":"Available Classes: NerBlackBox ExperimentResults ExperimentsResults NerModelPredict Usage: Python from nerblackbox import NerBlackBox , ExperimentResults , ExperimentsResults , NerModelPredict","title":"Python API"},{"location":"guide/custom_experiments/","text":"Custom Experiments An experiment is defined by an experiment configuration file ./data/experiment_configs/<experiment_name>.ini . Create your own custom experiment configuration with <experiment_name> = custom_experiment . Example: custom_experiment.ini [dataset] dataset_name = swedish_ner_corpus dataset_tags = iob prune_ratio_train = 0.1 # for testing prune_ratio_val = 1.0 prune_ratio_test = 1.0 [model] pretrained_model_name = af-ai-center/bert-base-swedish-uncased [settings] checkpoints = True logging_level = info multiple_runs = 3 [hparams] max_epochs = 20 monitor = val_loss min_delta = 0.0 patience = 2 mode = min lr_warmup_epochs = 1 lr_num_cycles = 4 [runA] batch_size = 16 max_seq_length = 64 lr_max = 2e-5 lr_schedule = constant [runB] batch_size = 32 max_seq_length = 128 lr_max = 3e-5 lr_schedule = cosine In the following, we will go through the different parameters step by step to see what they mean. Parameters An experiment configuration contains the following parameter groups : Dataset Model Settings Hyperparameters (Optional) Hyperparameters (Mandatory) Some parameters are mandatory (i.e. they have to be included in an experiment configuration), others are optional and are set to default values if not specified. 1. Dataset Key Mandatory Default Value Type Values Comment dataset_name Yes --- str e.g. conll2003 Built-in Dataset or Custom Dataset dataset_type Yes --- str iob, plain specify if dataset tags are in IOB or plain format prune_ratio_train No 1.0 float 0.0 - 1.0 fraction of train dataset to be used prune_ratio_val No 1.0 float 0.0 - 1.0 fraction of val dataset to be used prune_ratio_test No 1.0 float 0.0 - 1.0 fraction of test dataset to be used Example: custom_experiment.ini (Dataset) [dataset] dataset_name = swedish_ner_corpus dataset_tags = iob prune_ratio_train = 0.1 # for testing prune_ratio_val = 1.0 prune_ratio_test = 1.0 2. Model Key Mandatory Default Value Type Values Comment pretrained_model_name Yes --- str e.g. af-ai-center/bert-base-swedish-uncased Built-in Model or Custom Model Example: custom_experiment.ini (Model) [model] pretrained_model_name = af-ai-center/bert-base-swedish-uncased 3. Settings Key Mandatory Default Value Type Values Comment checkpoints No True bool True, False whether to save model checkpoints logging_level No info str info, debug choose logging level , debug is more verbose multiple_runs No 1 int 1+ choose how often each hyperparameter run is executed (to control for statistical uncertainties) Example: custom_experiment.ini (Settings) [settings] checkpoints = True logging_level = info multiple_runs = 3 4. Hyperparameters (Optional) Key Mandatory Default Value Type Values Comment max_epochs No 20 int 1+ maximum amount of training epochs monitor No val_loss str val_loss, val_acc metric to monitor for early stopping (acc = accuracy) min_delta No 0.0 float 0.0+ minimum amount of improvement (w.r.t. monitored metric) required to continue training (i.e. not employ early stopping) patience No 2 int 0+ number of epochs to wait for improvement w.r.t. monitored metric until early stopping is employed mode No min str min, max whether the optimum for the monitored metric is the minimum (val_loss) or maximum (val_acc) value lr_warmup_epochs No 1 int 0+ number of epochs to gradually increase the learning rate during the warm-up phase, gets translated to num_warmup_steps lr_num_cycles No 4 int 1+ num_cycles for lr_schedule = cosine or lr_schedule = cosine_with_hard_restarts Example: custom_experiment.ini (Hyperparameters Optional) [hparams] max_epochs = 20 monitor = val_loss min_delta = 0.0 patience = 2 mode = min lr_warmup_epochs = 1 lr_num_cycles = 4 5. Hyperparameters (Mandatory) Key Mandatory Default Value Type Values Comment batch_size Yes --- int e.g. 16, 32, 64 number of training samples in one batch max_seq_length Yes --- int e.g. 64, 128, 256 maximum sequence length used for model's input data lr_max Yes --- float e.g. 2e-5, 3e-5 maximum learning rate (after warm-up) for AdamW optimizer lr_schedule Yes --- str constant, linear, cosine, cosine_with_hard_restarts Learning Rate Schedule , i.e. how to vary the learning rate (after warm-up) Example: custom_experiment.ini (Hyperparameters Mandatory) [runA] batch_size = 16 max_seq_length = 64 lr_max = 2e-5 lr_schedule = constant [runB] batch_size = 32 max_seq_length = 128 lr_max = 3e-5 lr_schedule = cosine This creates 2 hyperparameter runs ( runA & runB ). Each hyperparameter run is executed multiple_runs times (see 3. Settings ).","title":"Custom Experiments"},{"location":"guide/custom_experiments/#custom-experiments","text":"An experiment is defined by an experiment configuration file ./data/experiment_configs/<experiment_name>.ini . Create your own custom experiment configuration with <experiment_name> = custom_experiment . Example: custom_experiment.ini [dataset] dataset_name = swedish_ner_corpus dataset_tags = iob prune_ratio_train = 0.1 # for testing prune_ratio_val = 1.0 prune_ratio_test = 1.0 [model] pretrained_model_name = af-ai-center/bert-base-swedish-uncased [settings] checkpoints = True logging_level = info multiple_runs = 3 [hparams] max_epochs = 20 monitor = val_loss min_delta = 0.0 patience = 2 mode = min lr_warmup_epochs = 1 lr_num_cycles = 4 [runA] batch_size = 16 max_seq_length = 64 lr_max = 2e-5 lr_schedule = constant [runB] batch_size = 32 max_seq_length = 128 lr_max = 3e-5 lr_schedule = cosine In the following, we will go through the different parameters step by step to see what they mean.","title":"Custom Experiments"},{"location":"guide/custom_experiments/#parameters","text":"An experiment configuration contains the following parameter groups : Dataset Model Settings Hyperparameters (Optional) Hyperparameters (Mandatory) Some parameters are mandatory (i.e. they have to be included in an experiment configuration), others are optional and are set to default values if not specified.","title":"Parameters"},{"location":"guide/custom_experiments/#1-dataset","text":"Key Mandatory Default Value Type Values Comment dataset_name Yes --- str e.g. conll2003 Built-in Dataset or Custom Dataset dataset_type Yes --- str iob, plain specify if dataset tags are in IOB or plain format prune_ratio_train No 1.0 float 0.0 - 1.0 fraction of train dataset to be used prune_ratio_val No 1.0 float 0.0 - 1.0 fraction of val dataset to be used prune_ratio_test No 1.0 float 0.0 - 1.0 fraction of test dataset to be used Example: custom_experiment.ini (Dataset) [dataset] dataset_name = swedish_ner_corpus dataset_tags = iob prune_ratio_train = 0.1 # for testing prune_ratio_val = 1.0 prune_ratio_test = 1.0","title":"1. Dataset"},{"location":"guide/custom_experiments/#2-model","text":"Key Mandatory Default Value Type Values Comment pretrained_model_name Yes --- str e.g. af-ai-center/bert-base-swedish-uncased Built-in Model or Custom Model Example: custom_experiment.ini (Model) [model] pretrained_model_name = af-ai-center/bert-base-swedish-uncased","title":"2. Model"},{"location":"guide/custom_experiments/#3-settings","text":"Key Mandatory Default Value Type Values Comment checkpoints No True bool True, False whether to save model checkpoints logging_level No info str info, debug choose logging level , debug is more verbose multiple_runs No 1 int 1+ choose how often each hyperparameter run is executed (to control for statistical uncertainties) Example: custom_experiment.ini (Settings) [settings] checkpoints = True logging_level = info multiple_runs = 3","title":"3. Settings"},{"location":"guide/custom_experiments/#4-hyperparameters-optional","text":"Key Mandatory Default Value Type Values Comment max_epochs No 20 int 1+ maximum amount of training epochs monitor No val_loss str val_loss, val_acc metric to monitor for early stopping (acc = accuracy) min_delta No 0.0 float 0.0+ minimum amount of improvement (w.r.t. monitored metric) required to continue training (i.e. not employ early stopping) patience No 2 int 0+ number of epochs to wait for improvement w.r.t. monitored metric until early stopping is employed mode No min str min, max whether the optimum for the monitored metric is the minimum (val_loss) or maximum (val_acc) value lr_warmup_epochs No 1 int 0+ number of epochs to gradually increase the learning rate during the warm-up phase, gets translated to num_warmup_steps lr_num_cycles No 4 int 1+ num_cycles for lr_schedule = cosine or lr_schedule = cosine_with_hard_restarts Example: custom_experiment.ini (Hyperparameters Optional) [hparams] max_epochs = 20 monitor = val_loss min_delta = 0.0 patience = 2 mode = min lr_warmup_epochs = 1 lr_num_cycles = 4","title":"4. Hyperparameters (Optional)"},{"location":"guide/custom_experiments/#5-hyperparameters-mandatory","text":"Key Mandatory Default Value Type Values Comment batch_size Yes --- int e.g. 16, 32, 64 number of training samples in one batch max_seq_length Yes --- int e.g. 64, 128, 256 maximum sequence length used for model's input data lr_max Yes --- float e.g. 2e-5, 3e-5 maximum learning rate (after warm-up) for AdamW optimizer lr_schedule Yes --- str constant, linear, cosine, cosine_with_hard_restarts Learning Rate Schedule , i.e. how to vary the learning rate (after warm-up) Example: custom_experiment.ini (Hyperparameters Mandatory) [runA] batch_size = 16 max_seq_length = 64 lr_max = 2e-5 lr_schedule = constant [runB] batch_size = 32 max_seq_length = 128 lr_max = 3e-5 lr_schedule = cosine This creates 2 hyperparameter runs ( runA & runB ). Each hyperparameter run is executed multiple_runs times (see 3. Settings ).","title":"5. Hyperparameters (Mandatory)"},{"location":"guide/datasets_and_models/","text":"Datasets and Models nerblackbox and its Command Line Interface & Python API work out of the box (see Getting Started ) for built-in datasets and models. Custom datasets and models can easily be included. Built-in Datasets Name Language Open Source Sample Type #Samples (Train, Val, Test) Directory Name Required Files Source CoNLL 2003 English Yes Sentence (14040, 3249, 3452) conll2003 --- Description ; Data Swedish NER Corpus Swedish Yes Sentence (4819, 2065, 2452) swedish_ner_corpus --- Description+Data SIC Swedish Yes Sentence (437, 187, 268) sic --- Description+Data SUC 3.0 Swedish No Sentence (71046, 1546, 1568) suc suc-*.conll Description Datasets are pre-processed and made available by: Open Source CLI nerbb download Python nerbb . download () Not Open Source create folder: mkdir ./data/datasets/<Directory Name> move Required Files manually to ./data/datasets/<Directory Name> set up dataset: CLI nerbb set_up_dataset <Directory Name> Python nerbb . set_up_dataset ( < Directory Name > ) Additional dataset details (tags, tag distribution, ..) can be found in ./data/datasets/<Directory Name>/analyze_data Built-in Models All built-in or community-uploaded BERT models of the transformers library Custom Datasets To include your own custom dataset, do the following: Create a folder ./data/datasets/<custom_dataset> with the following files: train.csv val.csv test.csv Each row of the respective *.csv files has to contain one training sample in the format <labels> <tab> <text> , e.g. 0 0 0 0 0 0 PER <tab> this is a sample with a person Use dataset_name = <custom_dataset> in your experiment configuration file . Custom Models To include your own custom model, do the following: Create a new folder ./data/pretrained_models/<custom_model> with the following files: config.json pytorch_model.bin vocab.txt <custom_model> must include the architecture type, e.g. bert Use pretrained_model_name = <custom_model> in your experiment configuration file .","title":"Datasets and Models"},{"location":"guide/datasets_and_models/#datasets-and-models","text":"nerblackbox and its Command Line Interface & Python API work out of the box (see Getting Started ) for built-in datasets and models. Custom datasets and models can easily be included.","title":"Datasets and Models"},{"location":"guide/datasets_and_models/#built-in-datasets","text":"Name Language Open Source Sample Type #Samples (Train, Val, Test) Directory Name Required Files Source CoNLL 2003 English Yes Sentence (14040, 3249, 3452) conll2003 --- Description ; Data Swedish NER Corpus Swedish Yes Sentence (4819, 2065, 2452) swedish_ner_corpus --- Description+Data SIC Swedish Yes Sentence (437, 187, 268) sic --- Description+Data SUC 3.0 Swedish No Sentence (71046, 1546, 1568) suc suc-*.conll Description Datasets are pre-processed and made available by: Open Source CLI nerbb download Python nerbb . download () Not Open Source create folder: mkdir ./data/datasets/<Directory Name> move Required Files manually to ./data/datasets/<Directory Name> set up dataset: CLI nerbb set_up_dataset <Directory Name> Python nerbb . set_up_dataset ( < Directory Name > ) Additional dataset details (tags, tag distribution, ..) can be found in ./data/datasets/<Directory Name>/analyze_data","title":"Built-in Datasets"},{"location":"guide/datasets_and_models/#built-in-models","text":"All built-in or community-uploaded BERT models of the transformers library","title":"Built-in Models"},{"location":"guide/datasets_and_models/#custom-datasets","text":"To include your own custom dataset, do the following: Create a folder ./data/datasets/<custom_dataset> with the following files: train.csv val.csv test.csv Each row of the respective *.csv files has to contain one training sample in the format <labels> <tab> <text> , e.g. 0 0 0 0 0 0 PER <tab> this is a sample with a person Use dataset_name = <custom_dataset> in your experiment configuration file .","title":"Custom Datasets"},{"location":"guide/datasets_and_models/#custom-models","text":"To include your own custom model, do the following: Create a new folder ./data/pretrained_models/<custom_model> with the following files: config.json pytorch_model.bin vocab.txt <custom_model> must include the architecture type, e.g. bert Use pretrained_model_name = <custom_model> in your experiment configuration file .","title":"Custom Models"},{"location":"guide/getting_started/","text":"Getting Started Use either the Command Line Interface (CLI) or the Python API . basic usage CLI nerbb --help Python from nerblackbox import NerBlackBox nerbb = NerBlackBox () 1. Initialization The following commands need to be executed once: initialization CLI nerbb init nerbb download # optional, if built-in datasets shall be used Python nerbb . init () nerbb . download () # optional, if built-in datasets shall be used This creates a ./data directory with the following structure: data/ \u2514\u2500\u2500 datasets \u2514\u2500\u2500 conll2003 # built-in dataset, requires download \u2514\u2500\u2500 train.csv \u2514\u2500\u2500 val.csv \u2514\u2500\u2500 test.csv \u2514\u2500\u2500 [..] # more built-in datasets, requires download \u2514\u2500\u2500 experiment_configs \u2514\u2500\u2500 default.ini # experiment config default values \u2514\u2500\u2500 my_experiment.ini # experiment config example \u2514\u2500\u2500 my_experiment_conll2003.ini # experiment config template \u2514\u2500\u2500 [..] # more experiment config templates \u2514\u2500\u2500 pretrained_models # custom model checkpoints \u2514\u2500\u2500 results 2. Experiment Fine-tuning a specific model on a specific dataset using specific training (hyper)parameters is called an experiment . An experiment is defined by an experiment configuration file ./data/experiment_configs/<experiment_name>.ini . One can view an experiment configuration as follows: show experiment configuration CLI nerbb show_experiment_config <experiment_name> Python nerbb . show_experiment_config ( \"<experiment_name>\" ) a. Use a predefined experiment For now, we use the predefined experiment configuration with <experiment_name> = my_experiment . b. Run an experiment Once an experiment is defined, the following command can be used to run it. run experiment CLI nerbb run_experiment <experiment_name> Python nerbb . run_experiment ( \"<experiment_name>\" ) c. Get experiment results Once an experiment is finished, one can inspect the main results or detailed results: get main results CLI nerbb get_experiment_results <experiment_name> # prints overview on runs Python experiment_results = nerbb . get_experiment_results ( \"<experiment_name>\" ) Python: see ExperimentResults for details on how to use experiment_results get detailed results & run histories using either mlflow or tensorboard CLI nerbb mlflow # + enter http://localhost:5000 in your browser nerbb tensorboard # + enter http://localhost:6006 in your browser d. Predict tags using the best model predict tags using the best model CLI # e.g. <text_input> = \"annotera den h\u00e4r texten\" nerbb predict <experiment_name> <text_input> Python # e.g. <text_input> = \"annotera den h\u00e4r texten\" nerbb . predict ( \"<experiment_name>\" , < text_input > ) # same but w/o having to reload the best model for multiple predictions experiment_results = nerbb . get_experiment_results ( < experiment_name > ) experiment_results . best_model . predict ( < text_input > ) Python: see NerModelPredict for details on how to use experiments_results.best_model 3. Experiments Overview Once one or more experiments have been run, the following commands can be used to access their results: get experiments overview CLI nerbb get_experiments Python nerbb . get_experiments () get overview on experiments' best runs CLI nerbb get_experiments_results Python experiments_results = nerbb . get_experiments_results () Python: see ExperimentsResults for details on how to use experiments_results 4. Next Steps Create your own Custom Experiments . See Datasets and Models for an overview on built-in datasets and models, and learn how to include your own custom datasets and models.","title":"Getting Started"},{"location":"guide/getting_started/#getting-started","text":"Use either the Command Line Interface (CLI) or the Python API . basic usage CLI nerbb --help Python from nerblackbox import NerBlackBox nerbb = NerBlackBox ()","title":"Getting Started"},{"location":"guide/getting_started/#1-initialization","text":"The following commands need to be executed once: initialization CLI nerbb init nerbb download # optional, if built-in datasets shall be used Python nerbb . init () nerbb . download () # optional, if built-in datasets shall be used This creates a ./data directory with the following structure: data/ \u2514\u2500\u2500 datasets \u2514\u2500\u2500 conll2003 # built-in dataset, requires download \u2514\u2500\u2500 train.csv \u2514\u2500\u2500 val.csv \u2514\u2500\u2500 test.csv \u2514\u2500\u2500 [..] # more built-in datasets, requires download \u2514\u2500\u2500 experiment_configs \u2514\u2500\u2500 default.ini # experiment config default values \u2514\u2500\u2500 my_experiment.ini # experiment config example \u2514\u2500\u2500 my_experiment_conll2003.ini # experiment config template \u2514\u2500\u2500 [..] # more experiment config templates \u2514\u2500\u2500 pretrained_models # custom model checkpoints \u2514\u2500\u2500 results","title":"1. Initialization"},{"location":"guide/getting_started/#2-experiment","text":"Fine-tuning a specific model on a specific dataset using specific training (hyper)parameters is called an experiment . An experiment is defined by an experiment configuration file ./data/experiment_configs/<experiment_name>.ini . One can view an experiment configuration as follows: show experiment configuration CLI nerbb show_experiment_config <experiment_name> Python nerbb . show_experiment_config ( \"<experiment_name>\" )","title":"2. Experiment"},{"location":"guide/getting_started/#a-use-a-predefined-experiment","text":"For now, we use the predefined experiment configuration with <experiment_name> = my_experiment .","title":"a. Use a predefined experiment"},{"location":"guide/getting_started/#b-run-an-experiment","text":"Once an experiment is defined, the following command can be used to run it. run experiment CLI nerbb run_experiment <experiment_name> Python nerbb . run_experiment ( \"<experiment_name>\" )","title":"b. Run an experiment"},{"location":"guide/getting_started/#c-get-experiment-results","text":"Once an experiment is finished, one can inspect the main results or detailed results: get main results CLI nerbb get_experiment_results <experiment_name> # prints overview on runs Python experiment_results = nerbb . get_experiment_results ( \"<experiment_name>\" ) Python: see ExperimentResults for details on how to use experiment_results get detailed results & run histories using either mlflow or tensorboard CLI nerbb mlflow # + enter http://localhost:5000 in your browser nerbb tensorboard # + enter http://localhost:6006 in your browser","title":"c. Get experiment results"},{"location":"guide/getting_started/#d-predict-tags-using-the-best-model","text":"predict tags using the best model CLI # e.g. <text_input> = \"annotera den h\u00e4r texten\" nerbb predict <experiment_name> <text_input> Python # e.g. <text_input> = \"annotera den h\u00e4r texten\" nerbb . predict ( \"<experiment_name>\" , < text_input > ) # same but w/o having to reload the best model for multiple predictions experiment_results = nerbb . get_experiment_results ( < experiment_name > ) experiment_results . best_model . predict ( < text_input > ) Python: see NerModelPredict for details on how to use experiments_results.best_model","title":"d. Predict tags using the best model"},{"location":"guide/getting_started/#3-experiments-overview","text":"Once one or more experiments have been run, the following commands can be used to access their results: get experiments overview CLI nerbb get_experiments Python nerbb . get_experiments () get overview on experiments' best runs CLI nerbb get_experiments_results Python experiments_results = nerbb . get_experiments_results () Python: see ExperimentsResults for details on how to use experiments_results","title":"3. Experiments Overview"},{"location":"guide/getting_started/#4-next-steps","text":"Create your own Custom Experiments . See Datasets and Models for an overview on built-in datasets and models, and learn how to include your own custom datasets and models.","title":"4. Next Steps"}]}